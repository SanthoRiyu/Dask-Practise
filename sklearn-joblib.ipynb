{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Scikit-Learn with Dask and Joblib\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/scikit-learn/scikit-learn/master/doc/logos/scikit-learn-logo-notext.png\"/> <img src=\"http://joblib.readthedocs.io/en/latest/_static/joblib_logo.svg\" width=\"20%\"/> \n",
    "\n",
    "Many Scikit-Learn operations already support parallelism with [joblib](http://joblib.readthedocs.io/) for single-machine parallelism. This lets you train most estimators (anything that accepts an `n_jobs` parameter) using all the cores of your laptop or workstation.\n",
    "\n",
    "Dask can scale these operations by replacing Joblib's single-machine system with a distributed cluster.  This lets you train those estimators using all the cores of your *cluster*, by changing one line of code. \n",
    "\n",
    "This is most useful for training large models on medium-sized datasets. You may have a large model when searching over many hyper-parameters, or when using an ensemble method with many individual estimators. For too small datasets, training times will typically be small enough that cluster-wide parallelism isn't helpful. For too large datasets (larger than a single machine's memory), the scikit-learn estimators may not be able to cope (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T22:08:23.335692Z",
     "start_time": "2019-03-23T22:08:03.534392Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Santhosh\\Anaconda3\\lib\\site-packages\\distributed\\bokeh\\core.py:57: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn('\\n' + msg)\n",
      "tornado.application - ERROR - Exception in callback <bound method Nanny.memory_monitor of <Nanny: tcp://127.0.0.1:58697, threads: 1>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Santhosh\\Anaconda3\\lib\\site-packages\\psutil\\_pswindows.py\", line 636, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\Santhosh\\Anaconda3\\lib\\site-packages\\psutil\\_pswindows.py\", line 752, in memory_info\n",
      "    t = self._get_raw_meminfo()\n",
      "  File \"C:\\Users\\Santhosh\\Anaconda3\\lib\\site-packages\\psutil\\_pswindows.py\", line 727, in _get_raw_meminfo\n",
      "    return cext.proc_memory_info(self.pid)\n",
      "ProcessLookupError: [Errno 3] No such process\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Santhosh\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 1229, in _run\n",
      "    return self.callback()\n",
      "  File \"C:\\Users\\Santhosh\\Anaconda3\\lib\\site-packages\\distributed\\nanny.py\", line 264, in memory_monitor\n",
      "    memory = proc.memory_info().rss\n",
      "  File \"C:\\Users\\Santhosh\\Anaconda3\\lib\\site-packages\\psutil\\_common.py\", line 340, in wrapper\n",
      "    return fun(self)\n",
      "  File \"C:\\Users\\Santhosh\\Anaconda3\\lib\\site-packages\\psutil\\__init__.py\", line 1046, in memory_info\n",
      "    return self._proc.memory_info()\n",
      "  File \"C:\\Users\\Santhosh\\Anaconda3\\lib\\site-packages\\psutil\\_pswindows.py\", line 641, in wrapper\n",
      "    raise NoSuchProcess(self.pid, self._name)\n",
      "psutil._exceptions.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=26236)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:58530\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:58533/status' target='_blank'>http://127.0.0.1:58533/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>12</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>34.08 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:58530' processes=11 cores=11>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client()\n",
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataset, Model, and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T22:08:45.107422Z",
     "start_time": "2019-03-23T22:08:38.130033Z"
    }
   },
   "outputs": [],
   "source": [
    "# import dask_ml.joblib  # register the distriubted backend\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use scikit-learn to create a pair of small random arrays, one for the features `X`, and one for the target `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T22:08:45.142104Z",
     "start_time": "2019-03-23T22:08:45.121119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06377997,  0.67640868,  1.06935647, -0.21758002,  0.46021477,\n",
       "        -0.39916689, -0.07918751,  1.20938491, -0.78531472, -0.17218611,\n",
       "        -1.08535744, -0.99311895,  0.30693511,  0.06405769, -1.0542328 ,\n",
       "        -0.52749607, -0.0741832 , -0.35562842,  1.05721416, -0.90259159],\n",
       "       [ 0.0708476 , -1.69528125,  2.44944917, -0.5304942 , -0.93296221,\n",
       "         2.86520354,  2.43572851, -1.61850016,  1.30071691,  0.34840246,\n",
       "         0.54493439,  0.22532411,  0.60556322, -0.19210097, -0.06802699,\n",
       "         0.9716812 , -1.79204799,  0.01708348, -0.37566904, -0.62323644],\n",
       "       [ 0.94028404, -0.49214582,  0.67795602, -0.22775445,  1.40175261,\n",
       "         1.23165333, -0.77746425,  0.01561602,  1.33171299,  1.08477266,\n",
       "        -0.97805157, -0.05012039,  0.94838552, -0.17342825, -0.47767184,\n",
       "         0.76089649,  1.00115812, -0.06946407,  1.35904607, -1.18958963],\n",
       "       [-0.29951677,  0.75988955,  0.18280267, -1.55023271,  0.33821802,\n",
       "         0.36324148, -2.10052547, -0.4380675 , -0.16639343, -0.34083531,\n",
       "         0.42435643,  1.17872434,  2.8314804 ,  0.14241375, -0.20281911,\n",
       "         2.40571546,  0.31330473,  0.40435568, -0.28754632, -2.8478034 ],\n",
       "       [-2.63062675,  0.23103376,  0.04246253,  0.47885055,  1.54674163,\n",
       "         1.6379556 , -1.53207229, -0.73444479,  0.46585484,  0.4738362 ,\n",
       "         0.98981401, -1.06119392, -0.88887952,  1.23840892, -0.57282854,\n",
       "        -1.27533949,  1.0030065 , -0.47712843,  0.09853558,  0.52780407]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, random_state=0)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fit a [Support Vector Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html), using [grid search](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to find the best value of the $C$ hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T22:08:45.166377Z",
     "start_time": "2019-03-23T22:08:45.161406Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\"C\": np.logspace(-3, 1, 30),\n",
    "              \"gamma\": [0.05, 0.5, 2],\n",
    "              \"kernel\": ['rbf', 'poly', 'sigmoid'],\n",
    "              \"shrinking\": [True, False]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(gamma='auto', random_state=0, probability=True),\n",
    "                           param_grid=param_grid,\n",
    "                           return_train_score=False,\n",
    "                           iid=True,\n",
    "                           cv=3,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on a Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit that normally, we'd call\n",
    "\n",
    "```python\n",
    "grid_search.fit(X, y)\n",
    "```\n",
    "\n",
    "To fit it using the cluster, we just need to use a context manager provided by joblib.\n",
    "We'll pre-scatter the data to each worker, which can help with performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T22:10:48.089018Z",
     "start_time": "2019-03-23T22:09:01.856510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# import dask_ml.joblib\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "with joblib.parallel_backend('dask', scatter=[X, y]):\n",
    "    grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit 1620 different models, one for each hyper-parameter and CV-split combination. The training was distributed across the cluster. At this point, we have a regular scikit-learn model, which can be used for prediction, scoring, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T22:10:48.219071Z",
     "start_time": "2019-03-23T22:10:48.124538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_shrinking</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.359617</td>\n",
       "      <td>0.010162</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.05, 'kernel': 'rbf', '...</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.377639</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>0.044737</td>\n",
       "      <td>0.024125</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>rbf</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.05, 'kernel': 'rbf', '...</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276921</td>\n",
       "      <td>0.020757</td>\n",
       "      <td>0.031485</td>\n",
       "      <td>0.017138</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>poly</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.05, 'kernel': 'poly', ...</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326826</td>\n",
       "      <td>0.026213</td>\n",
       "      <td>0.021993</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>poly</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.05, 'kernel': 'poly', ...</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.429173</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.036755</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.05, 'kernel': 'sigmoid...</td>\n",
       "      <td>0.502994</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.359617      0.010162         0.025397        0.007508   0.001   \n",
       "1       0.377639      0.004707         0.044737        0.024125   0.001   \n",
       "2       0.276921      0.020757         0.031485        0.017138   0.001   \n",
       "3       0.326826      0.026213         0.021993        0.012968   0.001   \n",
       "4       0.429173      0.000419         0.036755        0.015399   0.001   \n",
       "\n",
       "  param_gamma param_kernel param_shrinking  \\\n",
       "0        0.05          rbf            True   \n",
       "1        0.05          rbf           False   \n",
       "2        0.05         poly            True   \n",
       "3        0.05         poly           False   \n",
       "4        0.05      sigmoid            True   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'C': 0.001, 'gamma': 0.05, 'kernel': 'rbf', '...           0.502994   \n",
       "1  {'C': 0.001, 'gamma': 0.05, 'kernel': 'rbf', '...           0.502994   \n",
       "2  {'C': 0.001, 'gamma': 0.05, 'kernel': 'poly', ...           0.502994   \n",
       "3  {'C': 0.001, 'gamma': 0.05, 'kernel': 'poly', ...           0.502994   \n",
       "4  {'C': 0.001, 'gamma': 0.05, 'kernel': 'sigmoid...           0.502994   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.501502           0.501502            0.502        0.000704   \n",
       "1           0.501502           0.501502            0.502        0.000704   \n",
       "2           0.501502           0.501502            0.502        0.000704   \n",
       "3           0.501502           0.501502            0.502        0.000704   \n",
       "4           0.501502           0.501502            0.502        0.000704   \n",
       "\n",
       "   rank_test_score  \n",
       "0              395  \n",
       "1              395  \n",
       "2              395  \n",
       "3              395  \n",
       "4              395  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(grid_search.cv_results_)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The result is just a Scikit-Learn object\n",
    "\n",
    "Dask didn't replace Scikti-Learn, so everything is the same as you are accustomed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T22:10:48.489816Z",
     "start_time": "2019-03-23T22:10:48.446717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.986"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on training scikit-learn models with distributed joblib, see the [dask-ml documentation](http://dask-ml.readthedocs.io/en/latest/joblib.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
